```{r setup, include=FALSE}
library(rvest)
library(tidyverse)
library(reshape2)
library(ggplot2)
library(MASS)
library(dplyr)
library(knitr)
install.packages("gt")
library(gt)
install.packages("rlang")

set.seed(123)

fantasy_cleaned <- read.csv("/Users/oscardecastro/Desktop/fantasy_cleaned.csv")
fantasy_cleaned1 <- as_tibble(fantasy_cleaned, .name_repair = "unique")
fantasy_cleaned1$PPR <- as.numeric(fantasy_cleaned1$PPR)

df_filtered <- fantasy_cleaned1 
df_filtered$G <- as.integer(fantasy_cleaned1$G)
df_filtered <- df_filtered %>% filter(G > 7, FantPos != "FB") 
df_filtered <- df_filtered %>% rename_with(~ make.names(., unique = TRUE))
print(head(df_filtered))
```

# Density Plot
Visually it appears that with the exception of QB which is normally distributed the other positions are exponentially distributed. We will test wether this is true with Monte Carlo. 
```{r}
ggplot(df_filtered, aes(x = PPR, fill = FantPos)) + 
  geom_density(alpha = 0.5) +  
  labs(
    title = "Density Plot of Groups",
    x = "Value",
    y = "Density"
  ) +
  theme_minimal() +  
  scale_fill_brewer(palette = "Set2")  
```
It is important to mode the differences in data points by position which will influence variability
```{r}
count_by_position <- df_filtered %>%
  group_by(FantPos) %>%
  summarise(Count = n())

print(count_by_position)
kable(count_by_position, caption = "Number of Players by Position")
count_by_position %>%
  gt() %>%
  tab_header(title = "Number of Players by Position")
```

#Monte Carlo
WR: The p < 0.05, so we reject null hypothesis. The WR data does not fit an exponential distribution well.
RB: The p < 0.05, so we reject null hypothesis. The RB data does not fit an exponential distribution well.
TE: p = 0.065 > 0.05, so we fail to reject the null hypothesis. The TE data appears to fit an exponential distribution reasonably well.
QB: p = 0.124 > 0.05, so we fail to reject the null hypothesis. The QB data appears to fit a normal distribution reasonably well.
```{r}
#Extract observed data for each position
wr_data <- df_filtered %>% filter(FantPos == "WR", !is.na(PPR), is.finite(PPR), PPR >= 0) %>% pull(PPR)
rb_data <- df_filtered %>% filter(FantPos == "RB", !is.na(PPR), is.finite(PPR), PPR >= 0) %>% pull(PPR)
te_data <- df_filtered %>% filter(FantPos == "TE", !is.na(PPR), is.finite(PPR), PPR >= 0) %>% pull(PPR)
qb_data <- df_filtered %>% filter(FantPos == "QB", !is.na(PPR), is.finite(PPR), PPR >= 0) %>% pull(PPR)

#Fit Distributions
wr_fit <- fitdistr(wr_data, "exponential")
rb_fit <- fitdistr(rb_data, "exponential")
te_fit <- fitdistr(te_data, "exponential")
qb_fit <- fitdistr(qb_data, "normal")

#Kolmogorov-Smirnov Tests
wr_p_value <- ks.test(wr_data, "pexp", wr_fit$estimate)
rb_p_value <- ks.test(rb_data, "pexp", rb_fit$estimate)
te_p_value <- ks.test(te_data, "pexp", te_fit$estimate)
qb_p_value <- ks.test(qb_data, "pnorm", mean = qb_fit$estimate[1], sd = qb_fit$estimate[2])

cat("Kolmogorov-Smirnov Test P-Values:\n")
cat("WR:", wr_p_value$p.value, "\n")
cat("RB:", rb_p_value$p.value, "\n")
cat("TE:", te_p_value$p.value, "\n")
cat("QB:", qb_p_value$p.value, "\n")

#Monte Carlo Simulation Function
monte_carlo_cv <- function(n_sim, wr_params, rb_params, te_params, qb_params) {
  cv_values <- list(WR = numeric(n_sim), RB = numeric(n_sim), TE = numeric(n_sim), QB = numeric(n_sim))
  
  for (i in 1:n_sim) {
    # Draw samples based on fitted distributions
    wr_sample <- rexp(100, rate = wr_params)
    rb_sample <- rexp(100, rate = rb_params)
    te_sample <- rexp(100, rate = te_params)
    qb_sample <- rnorm(100, mean = qb_params[1], sd = qb_params[2])
    
    # Calculate CV for each position
    cv_values$WR[i] <- sd(wr_sample) / mean(wr_sample)
    cv_values$RB[i] <- sd(rb_sample) / mean(rb_sample)
    cv_values$TE[i] <- sd(te_sample) / mean(te_sample)
    cv_values$QB[i] <- sd(qb_sample) / mean(qb_sample)
  }
  
  return(cv_values)
}

#Run Monte Carlo Simulation
n_sim <- 10000
cv_results <- monte_carlo_cv(
  n_sim,
  wr_params = wr_fit$estimate,
  rb_params = rb_fit$estimate,
  te_params = te_fit$estimate,
  qb_params = qb_fit$estimate
)

cv_data <- data.frame(
  CV = c(cv_results$WR, cv_results$RB, cv_results$TE, cv_results$QB),
  Position = rep(c("WR", "RB", "TE", "QB"), each = n_sim)
)

ggplot(cv_data, aes(x = CV, fill = Position)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Monte Carlo Simulated CV Distribution by Position",
    x = "Coefficient of Variation",
    y = "Density"
  ) +
  theme_minimal()
```

#Bootstrap - Stratified by position 
We can see that there is no similarity between positions and their respective CV values compared to one another. We used bootstrap as it is not as dependent on variability as Monte Carlo. 
```{r}
# Bootstrap CV Function
bootstrap_cv <- function(data, n_bootstrap = 1000) {
  boot_cvs <- numeric(n_bootstrap)
  
  for (i in 1:n_bootstrap) {
    sample_data <- data %>% sample_frac(replace = TRUE)  # Sample with replacement
    mean_PPR <- mean(sample_data$PPR, na.rm = TRUE)
    sd_PPR <- sd(sample_data$PPR, na.rm = TRUE)
    boot_cvs[i] <- sd_PPR / mean_PPR
  }
  
  return(boot_cvs)
}

# Bootstrap CV by Positions
wr_data <- df_filtered %>% filter(FantPos == "WR")
wr_bootstrap <- bootstrap_cv(wr_data)

rb_data <- df_filtered %>% filter(FantPos == "RB")
rb_bootstrap <- bootstrap_cv(rb_data)

te_data <- df_filtered %>% filter(FantPos == "TE")
te_bootstrap <- bootstrap_cv(te_data)

qb_data <- df_filtered %>% filter(FantPos == "QB")
qb_bootstrap <- bootstrap_cv(qb_data)

# Combine Bootstrap Results
boot_data <- data.frame(
  CV = c(wr_bootstrap, rb_bootstrap, te_bootstrap, qb_bootstrap),
  Position = factor(rep(c("WR", "RB", "TE", "QB"), 
                        times = c(length(wr_bootstrap), length(rb_bootstrap), 
                                  length(te_bootstrap), length(qb_bootstrap))))
)

# Perform Pairwise T-Test
pairwise_result <- pairwise.t.test(
  boot_data$CV,
  boot_data$Position,
  p.adjust.method = "bonferroni"
)
print(pairwise_result)

calculate_ci <- function(bootstrap_cvs, conf_level = 0.95) {
  alpha <- 1 - conf_level
  ci_lower <- quantile(bootstrap_cvs, probs = alpha / 2, na.rm = TRUE)
  ci_upper <- quantile(bootstrap_cvs, probs = 1 - alpha / 2, na.rm = TRUE)
  return(c(Lower = ci_lower, Upper = ci_upper))
}

# Calculate CIs for each position
wr_ci <- calculate_ci(wr_bootstrap)
rb_ci <- calculate_ci(rb_bootstrap)
te_ci <- calculate_ci(te_bootstrap)
qb_ci <- calculate_ci(qb_bootstrap)

# Results
cat("Confidence Intervals for Bootstrap CV:\n")
cat("WR:", wr_ci, "\n")
cat("RB:", rb_ci, "\n")
cat("TE:", te_ci, "\n")
cat("QB:", qb_ci, "\n")

ggplot(boot_data, aes(x = CV, fill = Position)) + 
  geom_density(alpha = 0.5) + 
  labs(title = "Bootstrapped CV Distribution by Position", 
       x = "Coefficient of Variation", 
       y = "Density") +
  theme_minimal()
```



#Jackknife - measure the precision of the Bootstrap estimates 
```{r}
five_fold_cv_precision <- function(data, group_var, n_bootstrap = 1000, n_folds = 5) {
  grouped_data <- split(data, data[[group_var]])
  
  results <- list()

  for (group in names(grouped_data)) {
    group_data <- grouped_data[[group]]
    n <- nrow(group_data)
    
    fold_indices <- sample(rep(1:n_folds, length.out = n))
    fold_estimates <- numeric(n_folds)
    
    for (fold in 1:n_folds) {
      train_data <- group_data[fold_indices != fold, ]
      
      bootstrap_cvs <- numeric(n_bootstrap)
      for (j in 1:n_bootstrap) {
        sample_data <- sample(train_data$PPR, replace = TRUE)  # Bootstrap sampling
        bootstrap_cvs[j] <- sd(sample_data, na.rm = TRUE) / mean(sample_data, na.rm = TRUE)  # Compute CV
      }
      
      fold_estimates[fold] <- mean(bootstrap_cvs, na.rm = TRUE)
    }
    
    cross_validation_variance <- var(fold_estimates, na.rm = TRUE)
    
    results[[group]] <- list(
      fold_estimates = fold_estimates,
      cross_validation_variance = cross_validation_variance
    )
  }
  
  return(results)
}

# Apply 5-Fold 
kfold_results <- five_fold_cv_precision(df_filtered, group_var = "FantPos", n_bootstrap = 1000, n_folds = 5)

for (position in names(kfold_results)) {
  cat("Position:", position, "\n")
  cat("5-Fold Variance of Bootstrap CV:", kfold_results[[position]]$cross_validation_variance, "\n\n")
}

kfold_data <- do.call(rbind, lapply(names(kfold_results), function(pos) {
  data.frame(
    Position = pos,
    Fold_Estimates = kfold_results[[pos]]$fold_estimates
  )
}))

kfold_table %>%
  gt() %>%
  tab_header(
    title = "5-Fold Variance of Bootstrap CV by Position"
  ) %>%
  cols_label(
    Position = "Position",
    CrossValidationVariance = "5-Fold Variance"
  )
```

#Other Variables to Acknowledge
```{r}
anova1 <- aov(PPR ~ FantPos + Age + Tm + Year, data = df_filtered)
summary(anova1)
```

#Simulations

```{r}
# Simulated Data Generation Function
generate_synthetic_data <- function(n, fant_pos) {
  PPR <- case_when(
    fant_pos == "WR" ~ rexp(n,rate = 0.2),  
    fant_pos == "RB" ~ rexp(n, rate = 0.2),      
    fant_pos == "TE" ~ rexp(n, rate = 0.2),                 
    fant_pos == "QB" ~ rnorm(n, mean = 15, sd = 5),         
    TRUE ~ rnorm(n, mean = 10, sd = 3)                     
  )
  data.frame(FantPos = fant_pos, PPR = PPR)
}

set.seed(123)
n <- 1000  
sim_wr <- generate_synthetic_data(n, "WR")
sim_rb <- generate_synthetic_data(n, "RB")
sim_te <- generate_synthetic_data(n, "TE")
sim_qb <- generate_synthetic_data(n, "QB")
```

## Bootstrap Simulation

```{r}
# Bootstrap CV Function for Simulated Data
bootstrap_cv_simulation <- function(data, n_bootstrap = 1000) {
  boot_cvs <- numeric(n_bootstrap)
  
  for (i in 1:n_bootstrap) {
    # Sample with replacement
    sample_data <- data[sample(1:nrow(data), replace = TRUE), ]
    mean_PPR <- mean(sample_data$PPR, na.rm = TRUE)
    sd_PPR <- sd(sample_data$PPR, na.rm = TRUE)
    boot_cvs[i] <- sd_PPR / mean_PPR
  }
  
  return(boot_cvs)
}

# Run Bootstrap Simulation for Each Simulated Dataset
wr_bootstrap_sim <- bootstrap_cv_simulation(sim_wr)
rb_bootstrap_sim <- bootstrap_cv_simulation(sim_rb)
te_bootstrap_sim <- bootstrap_cv_simulation(sim_te)
qb_bootstrap_sim <- bootstrap_cv_simulation(sim_qb)

# Combine Bootstrap Results
sim_boot_data <- data.frame(
  CV = c(wr_bootstrap_sim, rb_bootstrap_sim, te_bootstrap_sim, qb_bootstrap_sim),
  Position = factor(rep(c("WR", "RB", "TE", "QB"), 
                        times = c(length(wr_bootstrap_sim), length(rb_bootstrap_sim), 
                                  length(te_bootstrap_sim), length(qb_bootstrap_sim))))
)
```

```{r}
# Perform Pairwise T-Test
pairwise_result_sim <- pairwise.t.test(
  sim_boot_data$CV,
  sim_boot_data$Position,
  p.adjust.method = "bonferroni"
)
print(pairwise_result_sim)
```

```{r}
# Confidence Interval Calculation Function
calculate_ci <- function(bootstrap_cvs, conf_level = 0.95) {
  alpha <- 1 - conf_level
  ci_lower <- quantile(bootstrap_cvs, probs = alpha / 2, na.rm = TRUE)
  ci_upper <- quantile(bootstrap_cvs, probs = 1 - alpha / 2, na.rm = TRUE)
  return(c(Lower = ci_lower, Upper = ci_upper))
}

# Calculate Confidence Intervals for Simulated Data
wr_ci_sim <- calculate_ci(wr_bootstrap_sim)
rb_ci_sim <- calculate_ci(rb_bootstrap_sim)
te_ci_sim <- calculate_ci(te_bootstrap_sim)
qb_ci_sim <- calculate_ci(qb_bootstrap_sim)

# Print Results
cat("Confidence Intervals for Simulated Bootstrap CV:\n")
cat("WR:", wr_ci_sim, "\n")
cat("RB:", rb_ci_sim, "\n")
cat("TE:", te_ci_sim, "\n")
cat("QB:", qb_ci_sim, "\n")

```

```{r}
# Visualize Bootstrap CV Distributions
ggplot(sim_boot_data, aes(x = CV, fill = Position)) + 
  geom_density(alpha = 0.5) + 
  labs(title = "Bootstrapped CV Distribution by Position (Simulated Data)", 
       x = "Coefficient of Variation", 
       y = "Density") +
  theme_minimal()
```

## Jackknife Simulation

```{r}
# Jackknife CV Function
jackknife_cv_simulation <- function(data) {
  n <- nrow(data)
  jackknife_estimates <- numeric(n)
  
  for (i in 1:n) {
    # Remove the i-th observation
    jackknife_sample <- data[-i, ]
    mean_PPR <- mean(jackknife_sample$PPR, na.rm = TRUE)
    sd_PPR <- sd(jackknife_sample$PPR, na.rm = TRUE)
    jackknife_estimates[i] <- sd_PPR / mean_PPR
  }
  
  # Calculate jackknife mean and variance
  jackknife_mean <- mean(jackknife_estimates, na.rm = TRUE)
  jackknife_variance <- (n - 1) * mean((jackknife_estimates - jackknife_mean)^2, na.rm = TRUE)
  
  return(list(estimates = jackknife_estimates, variance = jackknife_variance))
}

# Apply Jackknife Simulation for Each Simulated Dataset
wr_jackknife_sim <- jackknife_cv_simulation(sim_wr)
rb_jackknife_sim <- jackknife_cv_simulation(sim_rb)
te_jackknife_sim <- jackknife_cv_simulation(sim_te)
qb_jackknife_sim <- jackknife_cv_simulation(sim_qb)
```

```{r}
# Combine Jackknife Results
jackknife_data <- data.frame(
  CV = c(wr_jackknife_sim$estimates, rb_jackknife_sim$estimates, 
         te_jackknife_sim$estimates, qb_jackknife_sim$estimates),
  Position = factor(rep(c("WR", "RB", "TE", "QB"), 
                        times = c(length(wr_jackknife_sim$estimates), 
                                  length(rb_jackknife_sim$estimates), 
                                  length(te_jackknife_sim$estimates), 
                                  length(qb_jackknife_sim$estimates))))
)

# Summary of Jackknife Variance for Each Position
jackknife_variance_summary <- data.frame(
  Position = c("WR", "RB", "TE", "QB"),
  Variance = c(wr_jackknife_sim$variance, 
               rb_jackknife_sim$variance, 
               te_jackknife_sim$variance, 
               qb_jackknife_sim$variance)
)
print(jackknife_variance_summary)
```

```{r}
# Density Plot of Jackknife CV Estimates
ggplot(jackknife_data, aes(x = CV, fill = Position)) +
  geom_density(alpha = 0.5) +
  labs(
    title = "Jackknife CV Distribution by Position (Simulated Data)",
    x = "Coefficient of Variation",
    y = "Density"
  ) +
  theme_minimal()
```

```{r}
# Bar Chart of Jackknife Variance by Position
ggplot(jackknife_variance_summary, aes(x = Position, y = Variance, fill = Position)) +
  geom_bar(stat = "identity", alpha = 0.7) +
  labs(
    title = "Jackknife Variance by Position (Simulated Data)",
    x = "Position",
    y = "Variance"
  ) +
  theme_minimal()
```
